version: '3.8'

services:
  # ==========================================
  # 1. STORAGE LAYER (MinIO S3)
  # ==========================================
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 5s
      timeout: 5s
      retries: 5

# SERVICE TỰ ĐỘNG CONFIG
  minio-setup:
    image: minio/mc
    container_name: minio-setup
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: |
      /bin/sh -c "
      # 1. Vòng lặp chờ MinIO sẵn sàng (Dùng cú pháp alias set mới)
      until /usr/bin/mc alias set myminio http://minio:9000 minioadmin minioadmin; do
        echo '...Waiting for MinIO to be ready...';
        sleep 1;
      done;

      # 2. Tạo bucket
      /usr/bin/mc mb --ignore-existing myminio/warehouse;

      # 3. Set quyền Public
      /usr/bin/mc anonymous set public myminio/warehouse;
      
      echo '>>> SUCCESS: Bucket warehouse is now PUBLIC!';
      exit 0;
      "

  # ==========================================
  # 2. INGESTION LAYER (Kafka)
  # ==========================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports: ["2181:2181"]

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server=localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5

  kafka-setup:
      image: confluentinc/cp-kafka:7.5.0
      container_name: kafka-setup
      depends_on:
        kafka:
          condition: service_healthy
      env_file:
        - .env
      command: >
        bash -c "
          echo 'Waiting for Kafka to be ready...';
          cub kafka-ready -b kafka:9092 1 20 && \
          kafka-topics --create --if-not-exists --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 --topic stock-ticks && \
          echo '>>> TOPIC stock-ticks CREATED SUCCESSFULLY!';
        "

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8082:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      DYNAMIC_CONFIG_ENABLED: "true"

  kafka-producer:
    build:
      context: .
      dockerfile: kafka/Dockerfile
    container_name: kafka-producer
    depends_on:
      kafka:
        condition: service_healthy
    env_file:
      - .env
    restart: always

  # ==========================================
  # 3. PROCESSING LAYER (Spark)
  # ==========================================
  spark-master:
    build:
      context: .
      dockerfile: spark/Dockerfile
    image: custom-spark-image:latest
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --ip 0.0.0.0 --port 7077 --webui-port 8080
    ports:
      - "8080:8080"
      - "7077:7077"

  spark-worker:
    image: custom-spark-image:latest
    container_name: spark-worker
    depends_on: [spark-master]
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077 --webui-port 8081
    ports: ["8081:8081"]

  spark-job:
    image: custom-spark-image:latest
    container_name: spark-job
    depends_on:
      spark-master:
        condition: service_started
      kafka:
        condition: service_healthy
      # CHỈ CHẠY KHI MINIO SETUP XONG (Set public xong mới chạy)
      minio-setup:
        condition: service_completed_successfully
    command: >
      /opt/spark/bin/spark-submit 
      --master spark://spark-master:7077 
      /opt/spark/work-dir/processor.py

  # ==========================================
  # 4. SERVING LAYER
  # ==========================================
  duckdb:
    build:
      context: ./duckdb
      dockerfile: Dockerfile
    container_name: duckdb-analytics
    depends_on: [spark-job]
    environment:
      PYTHONUNBUFFERED: 1
    # Chạy file analytics
    command: python -u analytics.py

  bi:
    build:
      context: ./duckdb
      dockerfile: Dockerfile
    container_name: bi-dashboard
    depends_on: [spark-job]
    ports:
      - "8501:8501"
    environment:
      PYTHONUNBUFFERED: 1
    # Chạy file visualization
    command: streamlit run data_visualization.py

volumes:
  kafka_data:
  minio_data: